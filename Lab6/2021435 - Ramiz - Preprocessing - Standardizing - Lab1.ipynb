{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4abc1f33",
   "metadata": {},
   "source": [
    "# Basic Standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54c7c52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -1.  2.]\n",
      "[1. 1. 1.]\n",
      "[[0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "X_train = np.array([[ 1., -1.,  2.]])\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "# print(scaler)\n",
    "\n",
    "print(scaler.mean_)\n",
    "\n",
    "print(scaler.scale_)\n",
    "\n",
    "X_scaled = scaler.transform(X_train)\n",
    "print(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d24690",
   "metadata": {},
   "source": [
    "# Standardize the dataset first and apply the model using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad129646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X, y = make_classification(random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "pipe.fit(X_train, y_train)  # apply scaling on training data\n",
    "\n",
    "pipe.score(X_test, y_test)  # apply scaling on testing data, without leaking training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff26ebfa",
   "metadata": {},
   "source": [
    "# MiniMax Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e3ce0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.        , 1.        ],\n",
       "       [1.        , 0.5       , 0.33333333],\n",
       "       [0.        , 1.        , 0.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                    [ 2.,  0.,  0.],\n",
    "                    [ 0.,  1., -1.]])\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "X_train_minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4d7d48",
   "metadata": {},
   "source": [
    "# Quantile Standardizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ebae78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/student/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:2627: UserWarning: n_quantiles (1000) is greater than the total number of samples (112). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.3, 5.1, 5.8, 6.5, 7.9])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "quantile_transformer = preprocessing.QuantileTransformer(random_state=0)\n",
    "X_train_trans = quantile_transformer.fit_transform(X_train)\n",
    "X_test_trans = quantile_transformer.transform(X_test)\n",
    "np.percentile(X_train[:, 0], [0, 25, 50, 75, 100]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28225293",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bc43130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40824829, -0.40824829,  0.81649658],\n",
       "       [ 1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.70710678, -0.70710678]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[ 1., -1.,  2.],\n",
    "    [ 2.,  0.,  0.],\n",
    "    [ 0.,  1., -1.]]\n",
    "X_normalized = preprocessing.normalize(X, norm='l2')\n",
    "X_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa825bca",
   "metadata": {},
   "source": [
    "# Categorical Data Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4dd50950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]]\n",
      "[[1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "enc = preprocessing.OrdinalEncoder()\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X)\n",
    "print(enc.transform([['female', 'from Europe', 'uses Firefox']]))\n",
    "print(enc.transform([['male', 'from US', 'uses Safari']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fe7758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
